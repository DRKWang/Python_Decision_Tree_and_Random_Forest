{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f11a1f-12e3-47a0-8a0b-d42e3d1e6189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15a93a83-0058-4154-8af2-7c621237ea52",
   "metadata": {},
   "source": [
    "eventtime.toString() +\", \" +\n",
    "eventtime.getTime() +\", \" +\n",
    "mapCoordinate.latitude_deg  + \", \" +\n",
    "mapCoordinate.longitude_deg + \", \" +\n",
    "intentModelData[ALTITUDE_FT] +\", \"+\n",
    "intentModelData[GROUNDTRACK_DEG] +\", \"+\n",
    "intentModelData[GROUNDSPEED_KTS] +\", \"+\n",
    "intentModelData[VERTICALSPEED_FT_PER_MIN] +\", \"+\n",
    "winningVerticalModel.getLabel() +\", \"+\n",
    "winningHorizontalModel.getLabel() +\", \"+\n",
    "winningSpeedModel.getLabel();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d294b4e8-b76f-41ef-8e31-bca64391fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# read text file into pandas DataFrame and \n",
    "# create header \n",
    "import os\n",
    "Column_names = [\"TIME_str\", \"TIME_sec\", \"latitude\", \"longitude\", \"ALTITUDE_FT\", \"GROUNDTRACK_DEG\", \\\n",
    "            \"GROUNDSPEED_KTS\", \"VERTICALSPEED_FT_PER_MIN\", \"Vertical_label\",\\\n",
    "           \"Horizontal_label\", \"Speed_label\", \"Turn_rate_deg_per_sec\", \"REL_HEADING\", \"DIST_TO_DEST\", \"MANEUVER_ID\" ]\n",
    "Selected_col_names = [\"GROUNDSPEED_KTS\", \"VERTICALSPEED_FT_PER_MIN\",  \\\n",
    "                      \"DIST_TO_DEST\"]\n",
    "Target_category_name = \"Vertical_label\"\n",
    "data_name = \"HOLD_3\"\n",
    "cwd = os.getcwd()\n",
    "mypath = cwd + f\"/../data/{data_name}/\"\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b74046-2ee5-48ae-9f93-8abb146a3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for file_name in onlyfiles:\n",
    "    if \"Traj\" in file_name:\n",
    "        if count == 0:\n",
    "            file_path = mypath + file_name\n",
    "            df = pd.read_csv(file_path, sep=\",\", header=None)\n",
    "            df.columns = Column_names\n",
    "            X_df = df[Selected_col_names]\n",
    "            Y_target = df[Target_category_name]\n",
    "        else:\n",
    "            file_path = mypath + file_name\n",
    "            df_temp = pd.read_csv(file_path, sep=\",\", header=None)\n",
    "            df_temp.columns = Column_names\n",
    "            \n",
    "            X_df_temp = df_temp[Selected_col_names]\n",
    "            Y_target_temp = df_temp[Target_category_name]\n",
    "            X_df = pd.concat([X_df, X_df_temp])\n",
    "            Y_target = pd.concat([Y_target, Y_target_temp])\n",
    "        count +=1\n",
    "        # if count >= 10:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6fd7dc6-ef77-4d20-917b-7502aa6ad58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df[\"GROUNDSPEED_KTS\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d856c336-8eb0-4e8c-9641-2e92e43c59b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df[\"GROUNDSPEED_KTS\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cacb55b-1e94-481e-b878-bbbf5e6406d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'  Over 250 kts under 10000ft',\n",
       " ' Climb_Nominal',\n",
       " ' Descend_Nominal',\n",
       " ' MaintainCurrentAltitude',\n",
       " ' No Conclusion: Vertical'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names =  list(set(list(Y_target)))\n",
    "word_map_to_num = set(list(Y_target))\n",
    "print(\"category:\")\n",
    "word_map_to_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b6fa5e-ae32-42d0-9f77-ea2c02b8a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of points: 54570\n"
     ]
    }
   ],
   "source": [
    "n_sample = len(X_df)\n",
    "print(\"number of points:\", n_sample)\n",
    "X_df = X_df.head(n_sample)\n",
    "Y_target = Y_target.head(n_sample)\n",
    "Y = []\n",
    "for y in Y_target:\n",
    "    for idx, s in enumerate(word_map_to_num):\n",
    "        if s == y:\n",
    "            Y.append(idx)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3726cd2-9f25-4a86-afac-c92dd69b02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import dtreeviz\n",
    "from sklearn.tree import export_text\n",
    "# read text file into pandas DataFrame and \n",
    "# create header \n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# file_name_test = \"Traj_AAL80-11121269.dat\" # worst\n",
    "file_name_test = \"Traj_AAL245-11147798_L_HOLD.dat\" # normal\n",
    "\n",
    "file_path_test = mypath + file_name_test\n",
    "\n",
    "\n",
    "# file_name_test = \"Traj_AAL1252-11172342POS_HOLD.dat\"\n",
    "\n",
    "# file_path_test = cwd + \"/../data/HOLD/\" + file_name_test\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(file_path_test, sep=\",\", header=None)\n",
    "df_test.columns = Column_names\n",
    "X_df_test = df_test[Selected_col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47fd8dfb-3c52-431e-b223-2ccb5f1e438e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of testing points: 3407\n"
     ]
    }
   ],
   "source": [
    "print(\"number of testing points:\", len(X_df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7af9570d-b187-441f-a55f-bdad3d36af33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3407"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_target = df_test[Target_category_name]\n",
    "test_sample = len(X_df_test)\n",
    "X_df_test = X_df_test.head(test_sample)\n",
    "Z_target = Z_target.head(test_sample)\n",
    "Z = []\n",
    "for z in Z_target:\n",
    "    for idx, s in enumerate(word_map_to_num):\n",
    "        if s == z:\n",
    "            Z.append(idx)\n",
    "Z = np.array(Z)\n",
    "len(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5b8eb3-5726-4b22-9685-583669609672",
   "metadata": {},
   "source": [
    "## target 1: vertical_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0156167d-9a8f-4064-bff9-8113ccd3b93a",
   "metadata": {},
   "source": [
    "# Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6ff5d2-f643-45db-a2f5-e36bbf560346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8662451896646509\n"
     ]
    }
   ],
   "source": [
    "# Entropy, small tree with train data\n",
    "\n",
    "criterion = \"entropy\"\n",
    "max_depth = 5\n",
    "num_of_trees = 3\n",
    "rf = RandomForestClassifier(n_estimators=num_of_trees, max_depth=max_depth, min_samples_leaf=10)\n",
    "model= rf.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df))\n",
    "diff = res - Y\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)\n",
    "for tree_index in range(num_of_trees):\n",
    "    viz_model = dtreeviz.model(rf[tree_index], X_df, Y,\n",
    "                    target_name=\"target\",\n",
    "                    feature_names=list(X_df.columns),\n",
    "                    class_names=target_names)\n",
    "    \n",
    "    v = viz_model.view()     # render as SVG into internal object \n",
    "    v                 # pop up window\n",
    "    v.save(f\"{data_name}_all_{Target_category_name}_{criterion}_rf_tree_{tree_index}\" + f\"max_depth:{max_depth}\"  + \".svg\")  # optionally save as svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb120e9-709b-448c-aa03-0a61bf38d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {\n",
    "    \"GROUNDSPEED_KTS\": [\"very low\", \"low\", \"normal\", \"high\", \"very high\"],\n",
    "    \"VERTICALSPEED_FT_PER_MIN\": [\"very low\", \"low\", \"normal\", \"high\", \"very high\"],\n",
    "    \"Turn_rate_deg_per_sec\": [\"very low\", \"low\", \"normal\", \"high\", \"very high\"],\n",
    "    \"REL_HEADING\": [\"extremely left\", \"left\", \"straight\", \"right\", \"extremely right\"],\n",
    "    \"DIST_TO_DEST\": [\"extremely close\", \"close\", \"a little far\", \"far\", \"extremely far\"]\n",
    "}\n",
    "# five words needs 4 landmarks\n",
    "# seperate equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f4407f1-68c0-4922-9700-06181081a76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302585092994046"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "395e9be3-3177-4357-a616-6485df8f4451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text_in_words\n",
    "from sklearn.utils.validation import check_array , check_is_fitted\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, _criterion, _tree\n",
    "import matplotlib.pyplot as plt\n",
    "def compute_entropy(value):\n",
    "    rtn = 0\n",
    "    tot = np.sum(value)\n",
    "    probs = [v/tot for v in value]\n",
    "    for p in probs:\n",
    "        if p>= 0.001:\n",
    "            rtn += - p * np.log(p)\n",
    "    return rtn\n",
    "        \n",
    "def export_text_for_main_reasons(\n",
    "        X_df,\n",
    "        decision_tree,\n",
    "        *,\n",
    "        feature_names=None,\n",
    "        class_names=None,\n",
    "        max_depth=10,\n",
    "        spacing=3,\n",
    "        decimals=2,\n",
    "        show_weights=False,\n",
    "        show_prob = True,\n",
    "        crn_threshold = 0.1\n",
    "):\n",
    "\n",
    "    import copy\n",
    "    threshold_collection = dict()\n",
    "    if feature_names is not None:\n",
    "        feature_names = check_array(\n",
    "            feature_names, ensure_2d=False, dtype=None, ensure_min_samples=0\n",
    "        )\n",
    "    if class_names is not None:\n",
    "        class_names = check_array(\n",
    "            class_names, ensure_2d=False, dtype=None, ensure_min_samples=0\n",
    "        )\n",
    "\n",
    "    check_is_fitted(decision_tree)\n",
    "    tree_ = decision_tree.tree_\n",
    "    if is_classifier(decision_tree):\n",
    "        if class_names is None:\n",
    "            class_names = decision_tree.classes_\n",
    "        elif len(class_names) != len(decision_tree.classes_):\n",
    "            raise ValueError(\n",
    "                \"When `class_names` is an array, it should contain as\"\n",
    "                \" many items as `decision_tree.classes_`. Got\"\n",
    "                f\" {len(class_names)} while the tree was fitted with\"\n",
    "                f\" {len(decision_tree.classes_)} classes.\"\n",
    "            )\n",
    "    right_child_fmt = \"{} {} is {}\"\n",
    "    left_child_fmt = \"{} {} is {}\"\n",
    "    truncation_fmt = \"{} {}\\n\"\n",
    "\n",
    "    if feature_names is not None and len(feature_names) != tree_.n_features:\n",
    "        raise ValueError(\n",
    "            \"feature_names must contain %d elements, got %d\"\n",
    "            % (tree_.n_features, len(feature_names))\n",
    "        )\n",
    "\n",
    "    if isinstance(decision_tree, DecisionTreeClassifier):\n",
    "        value_fmt = \"{}{} weights: {}\\n\"\n",
    "        if not show_weights:\n",
    "            value_fmt = \"{}{}{}\\n\"\n",
    "    else:\n",
    "        value_fmt = \"{}{} value: {}\\n\"\n",
    "\n",
    "    if feature_names is not None:\n",
    "        feature_names_ = [\n",
    "            feature_names[i] if i != _tree.TREE_UNDEFINED else None\n",
    "            for i in tree_.feature\n",
    "        ]\n",
    "    else:\n",
    "        feature_names_ = [\"feature_{}\".format(i) for i in tree_.feature]\n",
    "\n",
    "    export_text.report = \"\"\n",
    "\n",
    "    def _add_leaf(value, class_name, indent, lower_bound_dict, upper_bound_dict, printable):\n",
    "        ## estiblish upper and lower dict for the features, upper collection the upper value, right child of the threshold, keep decreasing\n",
    "        # lower_bound_dict collect the lower value, left child of the threshold, keep increasing\n",
    "        #     right_child_fmt = \"{} {} <= {}\" left and right children are not corresponding to the graph, this is only for the tree,\n",
    "        #     left_child_fmt = \"{} {} > {}\" the tree is build from right small to left big\n",
    "        val = \"\"\n",
    "        is_classification = isinstance(decision_tree, DecisionTreeClassifier)\n",
    "        if show_weights or not is_classification:\n",
    "            val = [\"{1:.{0}f}, \".format(decimals, v) for v in value]\n",
    "            val = \"[\" + \"\".join(val)[:-2] + \"]\"\n",
    "        if is_classification:\n",
    "            val += \" class: \" + str(class_name)\n",
    "        export_text.report += value_fmt.format(indent, \"\", val)\n",
    "\n",
    "        ##\n",
    "        if printable:\n",
    "            output_conditions = []\n",
    "            all_feature_names = set(list(lower_bound_dict.keys()) + list(upper_bound_dict.keys()))\n",
    "            for key in all_feature_names:\n",
    "                cur_vocabulary = vocabulary[key]\n",
    "                interval_length = interval_length_collection[key]\n",
    "                cur_list = threshold_collection[key]\n",
    "                cur_words = []\n",
    "                if (key in lower_bound_dict.keys()) and (key in upper_bound_dict.keys()):\n",
    "                    for idx in range(len(cur_vocabulary)-1):\n",
    "                        left_range, right_range = cur_list[interval_length*idx], cur_list[interval_length*(idx+1)]\n",
    "                        if left_range <= lower_bound_dict[key] <= right_range or left_range <= upper_bound_dict[key] <= right_range:\n",
    "                            cur_words.append(cur_vocabulary[idx])\n",
    "                    right_range = cur_list[interval_length*(idx+1)]\n",
    "                    if lower_bound_dict[key] >= right_range or upper_bound_dict[key] >= right_range:\n",
    "                        cur_words.append(cur_vocabulary[-1])\n",
    "                    cur_range_txt = f\"(around {lower_bound_dict[key]:.02f} ~ {upper_bound_dict[key]:.02f})\"\n",
    "                    cur_condition = f\"{key} is \" + \" or \".join(cur_words) + cur_range_txt\n",
    "                    output_conditions.append(cur_condition)\n",
    "                    \n",
    "                elif (key in lower_bound_dict.keys()):\n",
    "                    for idx in range(len(cur_vocabulary)-1):\n",
    "                        left_range, right_range = cur_list[interval_length*idx], cur_list[interval_length*(idx+1)]\n",
    "                        if left_range <= lower_bound_dict[key] <= right_range:\n",
    "                            cur_words.append(cur_vocabulary[idx])\n",
    "                    right_range = cur_list[interval_length*(idx+1)]\n",
    "                    if lower_bound_dict[key] >= right_range:\n",
    "                        cur_words.append(cur_vocabulary[-1])\n",
    "                    cur_range_txt = f\"(> {lower_bound_dict[key]:.02f})\"\n",
    "                    cur_condition = f\"{key} is \" + \" or \".join(cur_words) + cur_range_txt\n",
    "                    output_conditions.append(cur_condition)\n",
    "\n",
    "                elif (key in upper_bound_dict.keys()):\n",
    "                    for idx in range(len(cur_vocabulary)-1):\n",
    "                        left_range, right_range = cur_list[interval_length*idx], cur_list[interval_length*(idx+1)]\n",
    "                        if left_range <= upper_bound_dict[key] <= right_range:\n",
    "                            cur_words.append(cur_vocabulary[idx])\n",
    "                    right_range = cur_list[interval_length*(idx+1)]\n",
    "                    if upper_bound_dict[key] >= right_range:\n",
    "                        cur_words.append(cur_vocabulary[-1])\n",
    "                    cur_range_txt = f\"(<= {upper_bound_dict[key]:.02f})\"\n",
    "                    cur_condition = f\"{key} is \" + \" or \".join(cur_words) + cur_range_txt\n",
    "                    output_conditions.append(cur_condition)\n",
    "            entropy = compute_entropy(value)\n",
    "            cur_number_of_node = np.sum(value)\n",
    "\n",
    "            CRN = entropy + (1 - cur_number_of_node/n_sample)\n",
    "            prob = np.max(value)/np.sum(value)*100\n",
    "            output_result = f\"then the entropy is {entropy:.2f}, the prob of the leaf node is {cur_number_of_node / n_sample:.2f}({int(cur_number_of_node)} data points), and the crn1 is {CRN:.2f},\"\n",
    "            output_res_2 = f\"the class is{str(class_name)}.\"\n",
    "            if CRN < 0.99:\n",
    "                print(\"If \" + \", and \".join(output_conditions) + \", \")\n",
    "                print(output_result)\n",
    "                print(output_res_2)\n",
    "                print()\n",
    "    def print_tree_recurse(node, depth, lower_bound_dict, upper_bound_dict, printable):\n",
    "        indent = \"\"\n",
    "\n",
    "        value = None\n",
    "        if tree_.n_outputs == 1:\n",
    "            value = tree_.value[node][0]\n",
    "        else:\n",
    "            value = tree_.value[node].T[0]\n",
    "        class_name = np.argmax(value)\n",
    "\n",
    "        if tree_.n_classes[0] != 1 and tree_.n_outputs == 1:\n",
    "            class_name = class_names[class_name]\n",
    "\n",
    "        if depth <= max_depth + 1:\n",
    "            info_fmt = \"\"\n",
    "            info_fmt_left = info_fmt\n",
    "            info_fmt_right = info_fmt\n",
    "\n",
    "            if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "                name = feature_names_[node] # the name of the feature in string\n",
    "                threshold = tree_.threshold[node] # the value of the threshold\n",
    "                # threshold = \"{1:.{0}f}\".format(decimals, threshold)\n",
    "                if not printable:\n",
    "                    if name not in threshold_collection:\n",
    "                        threshold_collection[name] = []\n",
    "                    else:\n",
    "                        threshold_collection[name].append(threshold)\n",
    "                export_text.report += right_child_fmt.format(indent, name, threshold) # output a line for the right child\n",
    "                export_text.report += info_fmt_left\n",
    "\n",
    "                # print_tree_recurse(tree_.children_left[node], depth + 1, cur_pre_text + right_child_fmt.format(indent, name, threshold) )\n",
    "                # print the less than case, right_child_fmt is corresponding to the <= case.\n",
    "                changed_upper_bound_dict = copy.deepcopy(upper_bound_dict)\n",
    "                changed_upper_bound_dict[name]= threshold\n",
    "                print_tree_recurse(tree_.children_left[node], depth + 1, lower_bound_dict, changed_upper_bound_dict, printable)\n",
    "\n",
    "                export_text.report += left_child_fmt.format(indent, name, threshold)\n",
    "                export_text.report += info_fmt_right\n",
    "                changed_lower_bound_dict = copy.deepcopy(lower_bound_dict)\n",
    "                changed_lower_bound_dict[name]=threshold\n",
    "                print_tree_recurse(tree_.children_right[node], depth + 1, changed_lower_bound_dict, upper_bound_dict, printable)\n",
    "            else:  # leaf\n",
    "                _add_leaf(value, class_name, indent, lower_bound_dict, upper_bound_dict, printable)\n",
    "        else:\n",
    "            subtree_depth = _compute_depth(tree_, node)\n",
    "            if subtree_depth == 1:\n",
    "                _add_leaf(value, class_name, indent)\n",
    "            else:\n",
    "                trunc_report = \"truncated branch of depth %d\" % subtree_depth\n",
    "                export_text.report += truncation_fmt.format(indent, trunc_report)\n",
    "\n",
    "    upper_bound_dict = dict()\n",
    "    lower_bound_dict = dict()\n",
    "    # construct the threshold_collection\n",
    "    print_tree_recurse(0, 1, lower_bound_dict, upper_bound_dict, printable = False)\n",
    "\n",
    "    # print the range of levels for each feature\n",
    "    interval_length_collection = dict()\n",
    "    for feature_name in Selected_col_names:\n",
    "        threshold_collection[feature_name].sort()\n",
    "        cur_list = threshold_collection[feature_name]\n",
    "        cur_vocal = vocabulary[feature_name]\n",
    "        interval_length = (len(cur_list)-1) // (len(cur_vocal)-1)\n",
    "        interval_length_collection[feature_name] = interval_length\n",
    "        # threshold_collection[0:intervals_length] is the first level\n",
    "        # threshold_collection[intervals_length:2*intervals_length] is the second level\n",
    "        # ...\n",
    "        print(f\"###########################################\")\n",
    "        print(f\"{r'feature name':^20} : {feature_name}\")\n",
    "        print(f\"{r'number of ranges':^20} : {len(cur_vocal)}\")\n",
    "        print(f\"-------------------------------------------\")\n",
    "        for i in range(len(cur_vocal)-1):\n",
    "            left_range = cur_list[interval_length*i]\n",
    "            right_range = cur_list[interval_length*(i+1)]\n",
    "            \n",
    "            print(f\"{cur_vocal[i]:^20} : [{left_range:.2f},{right_range:.2f}]\")\n",
    "        right_range = cur_list[interval_length*(i+1)]\n",
    "        print(f\"{cur_vocal[-1]:^20} :  >= {right_range:.2f}\")\n",
    "    print(f\"###########################################\")\n",
    "\n",
    "    \n",
    "    upper_bound_dict = dict()\n",
    "    lower_bound_dict = dict()\n",
    "    print_tree_recurse(0, 1, lower_bound_dict, upper_bound_dict, printable = True)\n",
    "\n",
    "    # print(threshold_collection)\n",
    "    return export_text.report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5e20f92-853d-4a18-baec-12c1294c5a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################################\n",
      "    feature name     : GROUNDSPEED_KTS\n",
      "  number of ranges   : 5\n",
      "-------------------------------------------\n",
      "      very low       : [174.50,306.50]\n",
      "        low          : [306.50,414.50]\n",
      "       normal        : [414.50,461.50]\n",
      "        high         : [461.50,470.50]\n",
      "     very high       :  >= 470.50\n",
      "###########################################\n",
      "    feature name     : VERTICALSPEED_FT_PER_MIN\n",
      "  number of ranges   : 5\n",
      "-------------------------------------------\n",
      "      very low       : [-416.00,-416.00]\n",
      "        low          : [-416.00,-416.00]\n",
      "       normal        : [-416.00,-416.00]\n",
      "        high         : [-416.00,-416.00]\n",
      "     very high       :  >= -416.00\n",
      "###########################################\n",
      "    feature name     : DIST_TO_DEST\n",
      "  number of ranges   : 5\n",
      "-------------------------------------------\n",
      "  extremely close    : [0.03,0.04]\n",
      "       close         : [0.04,0.04]\n",
      "    a little far     : [0.04,0.08]\n",
      "        far          : [0.08,0.53]\n",
      "   extremely far     :  >= 0.53\n",
      "###########################################\n",
      "If GROUNDSPEED_KTS is (<= 0.50), and DIST_TO_DEST is extremely close or close or far or extremely far(around 0.04 ~ 0.53), \n",
      "then the entropy is 0.00, the prob of the leaf node is 0.02(1187 data points), and the crn1 is 0.98,\n",
      "the class is No Conclusion: Vertical.\n",
      "\n",
      "If VERTICALSPEED_FT_PER_MIN is very high(> -160.00), and DIST_TO_DEST is extremely far(around 153.09 ~ 336.77), \n",
      "then the entropy is 0.11, the prob of the leaf node is 0.20(10967 data points), and the crn1 is 0.91,\n",
      "the class is MaintainCurrentAltitude.\n",
      "\n",
      "###########################################\n",
      "    feature name     : GROUNDSPEED_KTS\n",
      "  number of ranges   : 5\n",
      "-------------------------------------------\n",
      "      very low       : [0.50,2.00]\n",
      "        low          : [2.00,3.50]\n",
      "       normal        : [3.50,269.50]\n",
      "        high         : [269.50,283.50]\n",
      "     very high       :  >= 283.50\n",
      "###########################################\n",
      "    feature name     : VERTICALSPEED_FT_PER_MIN\n",
      "  number of ranges   : 5\n",
      "-------------------------------------------\n",
      "      very low       : [-1824.00,-544.00]\n",
      "        low          : [-544.00,-416.00]\n",
      "       normal        : [-416.00,-352.00]\n",
      "        high         : [-352.00,-160.00]\n",
      "     very high       :  >= -160.00\n",
      "###########################################\n",
      "    feature name     : DIST_TO_DEST\n",
      "  number of ranges   : 5\n",
      "-------------------------------------------\n",
      "  extremely close    : [0.03,0.04]\n",
      "       close         : [0.04,20.93]\n",
      "    a little far     : [20.93,28.56]\n",
      "        far          : [28.56,54.47]\n",
      "   extremely far     :  >= 54.47\n",
      "###########################################\n",
      "If GROUNDSPEED_KTS is very high(> 346.50), and VERTICALSPEED_FT_PER_MIN is very low(<= -1824.00), and DIST_TO_DEST is extremely far(<= 96.80), \n",
      "then the entropy is 0.00, the prob of the leaf node is 0.02(1266 data points), and the crn1 is 0.98,\n",
      "the class is Descend_Nominal.\n",
      "\n",
      "If GROUNDSPEED_KTS is very low(<= 0.50), and VERTICALSPEED_FT_PER_MIN is high or very high(around -224.00 ~ -96.00), and DIST_TO_DEST is extremely close or close(> 0.04), \n",
      "then the entropy is 0.00, the prob of the leaf node is 0.02(1171 data points), and the crn1 is 0.98,\n",
      "the class is No Conclusion: Vertical.\n",
      "\n",
      "If GROUNDSPEED_KTS is very high(> 407.50), and VERTICALSPEED_FT_PER_MIN is very high(> 224.00), \n",
      "then the entropy is 0.00, the prob of the leaf node is 0.01(685 data points), and the crn1 is 0.99,\n",
      "the class is Climb_Nominal.\n",
      "\n",
      "###########################################\n",
      "    feature name     : GROUNDSPEED_KTS\n",
      "  number of ranges   : 5\n",
      "-------------------------------------------\n",
      "      very low       : [306.50,348.50]\n",
      "        low          : [348.50,414.50]\n",
      "       normal        : [414.50,436.50]\n",
      "        high         : [436.50,461.50]\n",
      "     very high       :  >= 461.50\n",
      "###########################################\n",
      "    feature name     : VERTICALSPEED_FT_PER_MIN\n",
      "  number of ranges   : 5\n",
      "-------------------------------------------\n",
      "      very low       : [-992.00,-736.00]\n",
      "        low          : [-736.00,-544.00]\n",
      "       normal        : [-544.00,-160.00]\n",
      "        high         : [-160.00,416.00]\n",
      "     very high       :  >= 416.00\n",
      "###########################################\n",
      "    feature name     : DIST_TO_DEST\n",
      "  number of ranges   : 5\n",
      "-------------------------------------------\n",
      "  extremely close    : [0.00,32.92]\n",
      "       close         : [32.92,47.09]\n",
      "    a little far     : [47.09,61.49]\n",
      "        far          : [61.49,96.90]\n",
      "   extremely far     :  >= 96.90\n",
      "###########################################\n",
      "If VERTICALSPEED_FT_PER_MIN is low or normal(> -544.00), and GROUNDSPEED_KTS is very high(> 487.50), and DIST_TO_DEST is extremely far(> 153.05), \n",
      "then the entropy is 0.00, the prob of the leaf node is 0.03(1382 data points), and the crn1 is 0.97,\n",
      "the class is MaintainCurrentAltitude.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tree_index in range(num_of_trees):\n",
    "    r = export_text_for_main_reasons(X_df, rf[tree_index], feature_names=list(X_df.columns), class_names=target_names, show_weights=True, show_prob = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6224c4c5-c338-45db-a43a-2eb71ce20c17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtree_small_entropy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_graphviz\n\u001b[0;32m----> 3\u001b[0m dot_data \u001b[38;5;241m=\u001b[39m export_graphviz(X_df, \u001b[43mdtree_small_entropy\u001b[49m,\n\u001b[1;32m      4\u001b[0m                            feature_names\u001b[38;5;241m=\u001b[39mX_df\u001b[38;5;241m.\u001b[39mcolumns,  \n\u001b[1;32m      5\u001b[0m                            class_names \u001b[38;5;241m=\u001b[39m target_names,\n\u001b[1;32m      6\u001b[0m                            filled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \n\u001b[1;32m      7\u001b[0m                            rounded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m                             precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      9\u001b[0m                            proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m graph \u001b[38;5;241m=\u001b[39m graphviz\u001b[38;5;241m.\u001b[39mSource(dot_data)\n\u001b[1;32m     11\u001b[0m graph\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dtree_small_entropy' is not defined"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "dot_data = export_graphviz(X_df, dtree_small_entropy,\n",
    "                           feature_names=X_df.columns,  \n",
    "                           class_names = target_names,\n",
    "                           filled=False,  \n",
    "                           rounded = True,\n",
    "                            precision = 2,\n",
    "                           proportion=False)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = \"png\"\n",
    "graph.render(f\"{data_name}__all_{Target_category_name}_{criterion}\" + \"importances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919108c0-b6a4-43bd-a9cd-18258229a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = export_text(dtree_small_entropy, feature_names=list(X_df.columns), class_names=target_names, show_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccaed45-b3a9-4546-bec5-e01d4d8767e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776ccfb-df76-4f39-9c7e-b2db21ff6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = model.tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011733c7-9c8e-4e3a-b8a0-669846338068",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.children_left[tree.children_left[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf43acc1-570d-4898-912b-9aaf3942111d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = \"entropy\"\n",
    "dtree_small_entropy = DecisionTreeClassifier(criterion=criterion, max_depth=10, min_samples_leaf=20)   # (random_state=1234)\n",
    "model=dtree_small_entropy.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df))\n",
    "diff = res - Y\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)\n",
    "r = export_text(dtree_small_entropy, feature_names=list(X_df.columns), class_names=target_names, show_weights=False)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb07ad6-a06e-424d-a825-472b33b59ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entropy, large tree with train data\n",
    "\n",
    "criterion = \"entropy\"\n",
    "dtree_large_n = DecisionTreeClassifier(criterion=criterion)   # (random_state=1234)\n",
    "model=dtree_large_n.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df))\n",
    "diff = res - Y\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)\n",
    "r = export_text(dtree_large_n, feature_names=list(X_df.columns), class_names=target_names, show_weights=False)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902cd5cd-70f3-4bac-b323-9cf7fdb09e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entropy, large tree with test data\n",
    "\n",
    "criterion = \"entropy\"\n",
    "dtree_large_entropy = DecisionTreeClassifier(criterion=criterion)   # (random_state=1234)\n",
    "model=dtree_large_entropy.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df_test))\n",
    "diff = res - Z\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)\n",
    "r = export_text(dtree_large_entropy, feature_names=list(X_df.columns), class_names=target_names, show_weights=False)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1846f950-c522-4d40-89dd-576cbd2ea340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entropy, small tree with test data\n",
    "\n",
    "criterion = \"entropy\"\n",
    "dtree_small_entropy = DecisionTreeClassifier(criterion=criterion, max_depth=10, min_samples_leaf=20)   # (random_state=1234)\n",
    "model=dtree_small_entropy.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df_test))\n",
    "diff = res - Z\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)\n",
    "r = export_text(dtree_small_entropy, feature_names=list(X_df.columns), class_names=target_names, show_weights=False)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf95fe6-be73-4c8c-99e4-55fc27a15873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy, large rf with test data\n",
    "\n",
    "criterion = \"entropy\"\n",
    "num_of_trees = 3\n",
    "rf_small_entropy = RandomForestClassifier(n_estimators=num_of_trees)\n",
    "model=rf_small_entropy.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df_test))\n",
    "diff = res - Z\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7e669-7608-4714-8908-6140856a8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy, small rf with test data\n",
    "\n",
    "criterion = \"entropy\"\n",
    "num_of_trees = 3\n",
    "rf_small_entropy = RandomForestClassifier(n_estimators=num_of_trees, max_depth=5, min_samples_leaf=20)\n",
    "model=rf_small_entropy.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df_test))\n",
    "diff = res - Z\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f89306-46e6-44b1-8d2e-b91f39879bce",
   "metadata": {},
   "source": [
    "# Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498c990-e1a7-4716-8dab-c7a9c9b1349b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gini, small tree with train data\n",
    "\n",
    "criterion = \"gini\"\n",
    "dtree_small_gini = DecisionTreeClassifier(criterion=criterion, max_depth=5, min_samples_leaf=20)   # (random_state=1234)\n",
    "model=dtree_small_gini.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df))\n",
    "diff = res - Y\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)\n",
    "r = export_text(dtree_small_gini, feature_names=list(X_df.columns), class_names=target_names, show_weights=False)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d097c4-0d1c-4910-9a40-21fa0e51f2c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gini, large tree with train data\n",
    "criterion = \"gini\"\n",
    "dtree_large_gini = DecisionTreeClassifier(criterion=criterion)   # (random_state=1234)\n",
    "model=dtree_large_gini.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df))\n",
    "diff = res - Y\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)\n",
    "r = export_text(dtree_large_gini, feature_names=list(X_df.columns), class_names=target_names, show_weights=False)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78937ff-e516-4847-b3a5-937d4de184f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gini, large tree with test data\n",
    "\n",
    "criterion = \"gini\"\n",
    "dtree_large_gini = DecisionTreeClassifier(criterion=criterion)   # (random_state=1234)\n",
    "model=dtree_large_gini.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df_test))\n",
    "diff = res - Z\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)\n",
    "r = export_text(dtree_large_gini, feature_names=list(X_df.columns), class_names=target_names, show_weights=False)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb9cd1-f042-4ee1-bdd6-749c4d0bddea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gini, small tree with test data\n",
    "\n",
    "criterion = \"gini\"\n",
    "dtree_small_gini = DecisionTreeClassifier(criterion=criterion, max_depth=5, min_samples_leaf=20)   # (random_state=1234)\n",
    "model=dtree_small_gini.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df_test))\n",
    "diff = res - Z\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)\n",
    "r = export_text(dtree_small_gini, feature_names=list(X_df.columns), class_names=target_names, show_weights=False)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650402e3-d35a-49f9-8d72-e7c5a2488110",
   "metadata": {},
   "source": [
    "## Log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb684b70-dd9b-462c-b605-81c2404db6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6048453-2574-4190-8e03-3f939939117c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Log_loss, small tree with train data\n",
    "\n",
    "criterion = \"log_loss\"\n",
    "dtree_small_Log_loss = DecisionTreeClassifier(criterion=criterion, max_depth=5, min_samples_leaf=20)   # (random_state=1234)\n",
    "model=dtree_small_Log_loss.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df))\n",
    "diff = res - Y\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)\n",
    "r = export_text(dtree_small_Log_loss, feature_names=list(X_df.columns), class_names=target_names, show_weights=False)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d807c30-371e-4d62-80c1-677506711fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log_loss, large tree with train data\n",
    "criterion = \"log_loss\"\n",
    "dtree_large_Log_loss = DecisionTreeClassifier(criterion=criterion)   # (random_state=1234)\n",
    "model=dtree_large_Log_loss.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df))\n",
    "diff = res - Y\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d52c9-3964-460b-93c5-483b9f552ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log_loss, large tree with test data\n",
    "criterion = \"log_loss\"\n",
    "dtree_large_Log_loss = DecisionTreeClassifier(criterion=criterion)   # (random_state=1234)\n",
    "model=dtree_large_Log_loss.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df_test))\n",
    "diff = res - Z\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d07ae-15ce-459b-b704-69242dce253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log_loss, small tree with test data\n",
    "\n",
    "criterion = \"log_loss\"\n",
    "dtree_small_Log_loss = DecisionTreeClassifier(criterion=criterion, max_depth=5, min_samples_leaf=20)   # (random_state=1234)\n",
    "model=dtree_small_Log_loss.fit(X_df,Y)\n",
    "res = np.array(model.predict(X_df_test))\n",
    "diff = res - Z\n",
    "accuracy = 1/len(res) * sum([1 for x in diff if x == 0])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95e728-76f8-4d69-a9b6-aa17b67988df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565be90-edda-420c-ad73-ca1db274223a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
